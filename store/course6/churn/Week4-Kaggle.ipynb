{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Построение baseline моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Подготовка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импорт необходимых библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import FunctionTransformer, Imputer, StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import roc_auc_score, classification_report, roc_curve\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузка данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('orange_small_churn_train_data.csv', index_col='ID')\n",
    "test_df = pd.read_csv('orange_small_churn_test_data.csv', index_col='ID')\n",
    "\n",
    "y = train_df['labels'].apply(lambda x: 1 if x==1 else 0)\n",
    "X = train_df.drop(['labels'], axis=1)\n",
    "\n",
    "X_train, X_hold, \\\n",
    "y_train, y_hold = train_test_split(X, y,\n",
    "                                   test_size=0.2,\n",
    "                                   random_state=9,\n",
    "                                   shuffle=True,\n",
    "                                   stratify=y)\n",
    "X_test = test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуем препроцессинг данных.\n",
    "\n",
    "Данные содержат много пропусков и выбросов, а также константные признаки.\n",
    "Функция, находящие неконстантные признаки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def select_features(X_train, y_train):\n",
    "\n",
    "    # 1. filter out const columns\n",
    "    vc = X_train.apply(lambda col: len(col.value_counts()))\n",
    "    vc = vc[vc > 0]\n",
    "    all_cols = X_train.columns.values\n",
    "    num_cols = set(all_cols[:190])\n",
    "    cat_cols = set(all_cols[190:])\n",
    "    non_const_all_cols = set(vc.index.values)\n",
    "    non_const_num_cols = sorted(list(non_const_all_cols.intersection(num_cols)))\n",
    "    non_const_cat_cols = sorted(list(non_const_all_cols.intersection(cat_cols)))\n",
    "\n",
    "    print('non-const columns:', len(non_const_all_cols))\n",
    "\n",
    "    # 2. correlation feature selection\n",
    "\n",
    "    num_corrs = X_train[non_const_num_cols].apply(lambda col: point_biserial_corr(col.values, y_train), axis=0)\n",
    "    top_corrs = sorted(num_corrs.abs().sort_values(ascending=False)[:100].index)\n",
    "\n",
    "    all_cols = sorted(list(set(top_corrs).union(non_const_cat_cols)))\n",
    "\n",
    "    return all_cols, top_corrs, non_const_cat_cols\n",
    "\n",
    "\n",
    "def point_biserial_corr(x, y):\n",
    "    y = y[~np.isnan(x)]\n",
    "    x = x[~np.isnan(x)]\n",
    "    p = y.mean()\n",
    "    q = 1 - p\n",
    "    ex = x.mean()\n",
    "    sx = x.std(ddof=0)\n",
    "\n",
    "    px = x[y==1]\n",
    "    nx = x[y==0]\n",
    "\n",
    "    return (px.mean() - nx.mean())/sx*math.sqrt(p*q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция, исключающая выбросы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filter_outliers(X_train, y_train, cols, alpha):\n",
    "    print('filtering outliers...')\n",
    "    for col in cols:\n",
    "        var = X_train[col]\n",
    "        var_churn = var[y_train==1]\n",
    "        var_loyal = var[y_train==0]\n",
    "\n",
    "        outliers = len(X_train)\n",
    "        condition = None\n",
    "        col_a = alpha\n",
    "\n",
    "        while outliers > 200:\n",
    "            churn_min, churn_max = var_churn.quantile([col_a, 1 - col_a])\n",
    "            loyal_min, loyal_max = var_loyal.quantile([col_a, 1 - col_a])\n",
    "\n",
    "            condition = var.isnull() | \\\n",
    "                        ((y_train==1) & (churn_min <= var) & (var <= churn_max)) | \\\n",
    "                        ((y_train==0) & (loyal_min <= var) & (var <= loyal_max))\n",
    "\n",
    "            outliers = len(X_train) - len(X_train[condition])\n",
    "            col_a /= 2\n",
    "\n",
    "        if condition is not None:\n",
    "            X_train = X_train[condition]\n",
    "            y_train = y_train[condition]\n",
    "    print('finished: ', len(X_train))\n",
    "    \n",
    "    return X_train, y_train\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Выбросы исключим, а пропуски заполним средними значениями для случая числовых признаков и отдельным признаком для случая категориальных признаков. Кроме того, у некоторых категориальных признаков большое число возможных значений. Ограничим его, взяв только первые 200 наиболее часто встречаемых значения для каждого категориального признака.\n",
    "\n",
    "Нам потребуется отдельный класс, который будет делать dummy-encoding категориальных переменных с указанными выше особенностями"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DummyEncoder(BaseEstimator, TransformerMixin):\n",
    "    '''\n",
    "    Encodes categorical features as one-hot variables with max_categories restriction\n",
    "    '''\n",
    "    def __init__(self, columns=None, max_categories=None):\n",
    "        self.columns = columns\n",
    "        self.dummy_columns = None\n",
    "        self.max_categories = max_categories\n",
    "\n",
    "\n",
    "    def fit(self, X, y=None, **kwargs):\n",
    "        self.dummy_columns = None\n",
    "        return self\n",
    "\n",
    "\n",
    "    def transform(self, X, y=None, **kwargs):\n",
    "        if self.max_categories is not None:\n",
    "            X = X[self.columns] if self.columns is not None else X.copy()\n",
    "            for col in X.columns:\n",
    "                top_cats = X[col].value_counts()[:self.max_categories].index.values\n",
    "                X[col] = X[col].apply(lambda x: x if (x in top_cats or x is None) else 'aggr')\n",
    "\n",
    "        dummy_df = pd.get_dummies(X, columns=self.columns, sparse=True, dummy_na=True)\n",
    "        new_cols = dummy_df.columns.values\n",
    "        if self.dummy_columns is None:\n",
    "            self.dummy_columns = new_cols\n",
    "            return dummy_df\n",
    "        else:\n",
    "            res_df = pd.DataFrame()\n",
    "            for col in self.dummy_columns:\n",
    "                res_df[col] = dummy_df[col] if col in new_cols else np.zeros((len(X),), dtype=int)\n",
    "        return res_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как будет использоваться кросс-валидация, даже baseline модели нужно тренировать в пайплайне, чтобы информация о holdout-выборке не использовалась при обучении. Пайплайн будет:\n",
    "- Фильтровать выбросы (только для обучающей выборки перед обучением)\n",
    "- Удалять полностью NaN признаки\n",
    "- Запонять средними значенийми пропуски числовых переменных\n",
    "- Масштабировать числовые переменные\n",
    "- Dummy-кодировать категориальные переменные по описанному выше алгоритму\n",
    "\n",
    "Реализуем функцию, реализующую препроцессинг и конструирующую пайплайн:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_and_get_pipeline(X_train, y_train, alg):\n",
    "\n",
    "    # filter out outliers\n",
    "    X_train, y_train = filter_outliers(X_train, y_train, X_train.columns[:190], 0.01)\n",
    "    \n",
    "    # select features\n",
    "    all_cols, num_cols, cat_cols = select_features(X_train, y_train)\n",
    "    \n",
    "    pipeline = Pipeline(steps=[\n",
    "            # get rid of fully NaN columns\n",
    "            ('filter_out_useless_columns', FunctionTransformer(lambda data: data.loc[:, all_cols], validate=False)),\n",
    "\n",
    "            # processing\n",
    "            ('processing', FeatureUnion([\n",
    "\n",
    "                # numeric features\n",
    "                ('numeric', Pipeline(steps=[\n",
    "                    ('selecting', FunctionTransformer(lambda data: data.loc[:, num_cols], validate=False)),\n",
    "                    ('float_nan_mean', Imputer(strategy='mean')),\n",
    "                    ('scaling', StandardScaler())\n",
    "                ])),\n",
    "\n",
    "                # categorical features\n",
    "                ('categorical', Pipeline(steps=[\n",
    "                    ('selecting', FunctionTransformer(lambda data: data.loc[:, cat_cols], validate=False)),\n",
    "                    ('encoding', DummyEncoder(max_categories=200))\n",
    "                ]))\n",
    "            ])),\n",
    "\n",
    "            #model\n",
    "            ('model', alg)\n",
    "        ])\n",
    "\n",
    "    return X_train, y_train, pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Моделирование"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Будем использовать градиентный бустинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filtering outliers...\n",
      "finished:  25749\n",
      "non-const columns: 212\n",
      "Fitting 7 folds for each of 1 candidates, totalling 7 fits\n",
      "[CV] model__learning_rate=0.1, model__n_estimators=120 ...............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:60: RuntimeWarning: Mean of empty slice.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:60: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  model__learning_rate=0.1, model__n_estimators=120, score=0.775042813220856, total=  46.6s\n",
      "[CV] model__learning_rate=0.1, model__n_estimators=120 ...............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   57.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  model__learning_rate=0.1, model__n_estimators=120, score=0.7381874382240585, total=  48.3s\n",
      "[CV] model__learning_rate=0.1, model__n_estimators=120 ...............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  1.9min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  model__learning_rate=0.1, model__n_estimators=120, score=0.7197986127250299, total=  46.4s\n",
      "[CV] model__learning_rate=0.1, model__n_estimators=120 ...............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  2.9min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  model__learning_rate=0.1, model__n_estimators=120, score=0.7609671371364214, total=  44.5s\n",
      "[CV] model__learning_rate=0.1, model__n_estimators=120 ...............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  3.8min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  model__learning_rate=0.1, model__n_estimators=120, score=0.7679817249763127, total=  44.0s\n",
      "[CV] model__learning_rate=0.1, model__n_estimators=120 ...............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  4.7min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  model__learning_rate=0.1, model__n_estimators=120, score=0.768004630208985, total=  44.0s\n",
      "[CV] model__learning_rate=0.1, model__n_estimators=120 ...............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:  5.6min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  model__learning_rate=0.1, model__n_estimators=120, score=0.7520151018109659, total=  44.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:  6.5min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:  6.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model__learning_rate': 0.1, 'model__n_estimators': 120}\n",
      "0.75457201929\n"
     ]
    }
   ],
   "source": [
    "model = XGBClassifier(learning_rate=0.1, n_estimators=100, n_jobs=-1)\n",
    "params = {\n",
    "    'model__learning_rate': [0.1],\n",
    "    'model__n_estimators':  [120] }\n",
    "\n",
    "X_train, y_train, pipeline = preprocess_and_get_pipeline(X_train, y_train, model)\n",
    "\n",
    "cv = StratifiedKFold(n_splits=7, shuffle=True, random_state=9)\n",
    "\n",
    "grid = GridSearchCV(pipeline, params, scoring='roc_auc', cv=cv, verbose=10)\n",
    "grid.fit(X_train, y_train)\n",
    "print(grid.best_params_)\n",
    "print(grid.best_score_)\n",
    "\n",
    "model = grid.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитаем качество на отложенной выборке:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Holdout score: 0.728070744841\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict_proba(X_hold)[:, 1]\n",
    "score = roc_auc_score(y_hold, y_pred)\n",
    "print('Holdout score:', score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Обучим модель на всей тренировочной выборке с параметрами, полученными выше, и предскажем результаты тестовой:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filtering outliers...\n",
      "finished:  33115\n",
      "non-const columns: 212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:60: RuntimeWarning: Mean of empty slice.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:60: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    }
   ],
   "source": [
    "model = XGBClassifier(learning_rate=0.1, n_estimators=120, n_jobs=-1)\n",
    "X_train, y_train, pipeline = preprocess_and_get_pipeline(X, y, model)\n",
    "\n",
    "pipeline.fit(X, y)\n",
    "\n",
    "y_pred = pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "res_df = pd.DataFrame(y_pred, columns=['result'])\n",
    "res_df.index.name = 'ID'\n",
    "res_df.to_csv('churn_res.csv', sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Результат"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Private Score: 0.73519\n",
    "\n",
    "Public Score:  0.69487"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import recall_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split, cross_validate,StratifiedKFold\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\swink_000\\Anaconda2\\lib\\site-packages\\pandas\\core\\frame.py:2450: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[k1] = value[k2]\n"
     ]
    }
   ],
   "source": [
    "def dataframe_preprocess(df):\n",
    "    df_float = df.select_dtypes(include=[np.float])\n",
    "    df_object = df.select_dtypes(include=['object'])\n",
    "    used_cat_cols = []\n",
    "    #Выберем те признаки, в которых категорий не большое количество\n",
    "    for col in df_object.columns:\n",
    "        if len(df_object[col].unique()) <= 50:\n",
    "            used_cat_cols.append(col) \n",
    "\n",
    "    df = df[list(df_float.columns) + used_cat_cols + ['label']]\n",
    "    \n",
    "    #Заменим NaN значения нулями для численных, а категориальные NaN заменим еще одной категорией, которая будет обозначать, \n",
    "    #что данных нет\n",
    "    df[list(df_float.columns)] = df[list(df_float.columns)].fillna(0)\n",
    "    df[used_cat_cols] = df[used_cat_cols].fillna('Not given')\n",
    "    df = pd.get_dummies(df, columns = list(used_cat_cols))\n",
    "    \n",
    "    label = df.pop('label')\n",
    "    df['label']=label\n",
    "    return df\n",
    "\n",
    "new_df = dataframe_preprocess(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Scores\n",
      "Train Scores:\n",
      "Recall Score = 0.917763890719\n",
      "AUC-ROC Score = 0.549447008382\n",
      "F1 Score = 0.917763890719\n",
      "Precison Score = 0.917763890719\n",
      "Accuracy Score = 0.917763890719\n",
      "\n",
      "\n",
      "Test Scores:\n",
      "Recall Score = 0.9175000896\n",
      "AUC-ROC Score = 0.543352848328\n",
      "F1 Score = 0.9175000896\n",
      "Precison Score = 0.9175000896\n",
      "Accuracy Score = 0.9175000896\n",
      "-------------------------------------\n",
      "Random Forest Scores\n",
      "Train Scores:\n",
      "Recall Score = 0.985093742869\n",
      "AUC-ROC Score = 0.999808311498\n",
      "F1 Score = 0.985093742869\n",
      "Precison Score = 0.985093742869\n",
      "Accuracy Score = 0.985093742869\n",
      "\n",
      "\n",
      "Test Scores:\n",
      "Recall Score = 0.926156350211\n",
      "AUC-ROC Score = 0.597830715571\n",
      "F1 Score = 0.926156350211\n",
      "Precison Score = 0.926156350211\n",
      "Accuracy Score = 0.926156350211\n",
      "-------------------------------------\n",
      "Gradient Boosting Scores\n",
      "Train Scores:\n",
      "Recall Score = 0.928260415495\n",
      "AUC-ROC Score = 0.792091489219\n",
      "F1 Score = 0.928260415495\n",
      "Precison Score = 0.928260415495\n",
      "Accuracy Score = 0.928260415495\n",
      "\n",
      "\n",
      "Test Scores:\n",
      "Recall Score = 0.926156330679\n",
      "AUC-ROC Score = 0.736191318343\n",
      "F1 Score = 0.926156330679\n",
      "Precison Score = 0.926156330679\n",
      "Accuracy Score = 0.926156330679\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#В качестве бейслайн модлей выбрем линейную модель и два ансамблевыех метода со дефолтными параметрами\n",
    "models = [LogisticRegression(random_state = 42), RandomForestClassifier(random_state = 42), \n",
    "          GradientBoostingClassifier(random_state = 42)]\n",
    "model_names = ['Logistic Regression Scores', 'Random Forest Scores', 'Gradient Boosting Scores']\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10)\n",
    "\n",
    "scoring = {'recall': 'recall_micro',\n",
    "          'auc':'roc_auc',\n",
    "          'f_score':'f1_micro',\n",
    "           'prec':'precision_micro',\n",
    "          'acc':'accuracy'}\n",
    "\n",
    "for model, model_name in zip(models, model_names):\n",
    "    print model_name\n",
    "    scores = cross_validate(model, new_df.iloc[:,:-1], new_df['label'], scoring=scoring,\n",
    "                             cv=skf, return_train_score = True)\n",
    "    print 'Train Scores:'\n",
    "    print 'Recall Score = {0}'.format(scores['train_recall'].mean())\n",
    "    print 'AUC-ROC Score = {0}'.format(scores['train_auc'].mean())\n",
    "    print 'F1 Score = {0}'.format(scores['train_f_score'].mean())\n",
    "    print 'Precison Score = {0}'.format(scores['train_prec'].mean())\n",
    "    print 'Accuracy Score = {0}'.format(scores['train_acc'].mean())\n",
    "    print '\\n'\n",
    "    print 'Test Scores:'\n",
    "    print 'Recall Score = {0}'.format(scores['test_recall'].mean())\n",
    "    print 'AUC-ROC Score = {0}'.format(scores['test_auc'].mean())\n",
    "    print 'F1 Score = {0}'.format(scores['test_f_score'].mean())\n",
    "    print 'Precison Score = {0}'.format(scores['test_prec'].mean())\n",
    "    print 'Accuracy Score = {0}'.format(scores['test_acc'].mean())\n",
    "    print '-------------------------------------'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

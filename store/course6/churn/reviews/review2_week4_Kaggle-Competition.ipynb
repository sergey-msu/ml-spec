{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Построение и оптимизация модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from mlxtend.evaluate import lift_score\n",
    "from sklearn.metrics import make_scorer\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('orange_small_churn_train_data.csv')\n",
    "df_test = pd.read_csv('orange_small_churn_test_data.csv')\n",
    "target = 'labels'\n",
    "IDcol = 'ID'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_columns = df.select_dtypes(include='object').columns\n",
    "df[cat_columns] = df[cat_columns].astype(np.str)\n",
    "df_test[cat_columns] = df_test[cat_columns].astype(np.str)\n",
    "df.loc[df[target]==-1, target] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# вспомогательная функция для кодирования всех категориальных признаков\n",
    "class MultiColumnLabelEncoder:\n",
    "    def __init__(self, columns=None):\n",
    "        self.columns = columns\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        res = X.copy()\n",
    "        if self.columns is not None:\n",
    "            for col in self.columns:\n",
    "                res[col] = LabelEncoder().fit_transform(res[col])\n",
    "        else:\n",
    "            for colname, col in res.iteritems():\n",
    "                res[colname] = LabelEncoder().fit_transform(col)\n",
    "        return res\n",
    "\n",
    "    def fit_transform(self, X, y=None):\n",
    "        return self.fit(X, y).transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# закодируем категориальные признакии с помощью Label Encoder\n",
    "encoder = MultiColumnLabelEncoder(columns=cat_columns)\n",
    "df = encoder.fit_transform(df)\n",
    "df_test = encoder.transform(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# разобъем выборку на обучающую и валидационную\n",
    "train, test, y_train, y_test = train_test_split(df.drop(target, axis=1), df[target],\n",
    "                                                stratify=df[target], test_size=0.3, random_state=42)\n",
    "train[target] = y_train.values\n",
    "test[target] = y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelfit(alg, dtrain, predictors, useTrainCV=True, cv_folds=5, early_stopping_rounds=100):\n",
    "    if useTrainCV:\n",
    "        xgb_param = alg.get_xgb_params()\n",
    "        xgtrain = xgb.DMatrix(dtrain[predictors].values, label=dtrain[target].values)\n",
    "        cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'], nfold=cv_folds, stratified=True,\n",
    "            metrics='auc', early_stopping_rounds=early_stopping_rounds, verbose_eval=False, seed=27)\n",
    "        alg.set_params(n_estimators=cvresult.shape[0])\n",
    "    \n",
    "    alg.fit(dtrain[predictors], dtrain[target], early_stopping_rounds=early_stopping_rounds, verbose=False,\n",
    "            eval_metric='auc', eval_set=[(dtrain[predictors], dtrain[target]), (test[predictors], test[target])])\n",
    "        \n",
    "    test_predictions = alg.predict(test[predictors])\n",
    "    test_predprob = alg.predict_proba(test[predictors])[:,1]\n",
    "        \n",
    "    print(\"Accuracy : %.4g\" % metrics.accuracy_score(test[target].values, test_predictions))\n",
    "    print(\"PR-AUC: %.4g\" % metrics.average_precision_score(test[target], test_predictions))\n",
    "    print(\"ROC-AUC: %.4g\" % metrics.roc_auc_score(test[target], test_predprob))\n",
    "    print(\"F1: %.4g\" % metrics.f1_score(test[target], test_predictions))\n",
    "    print(\"Presision: %.4g\" % metrics.precision_score(test[target], test_predictions))\n",
    "    print(\"Recall: %.4g\" % metrics.recall_score(test[target], test_predictions))\n",
    "    print(\"Lift : %.4g\" % lift_score(test[target], test_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.9156\n",
      "PR-AUC: 0.1035\n",
      "ROC-AUC: 0.7346\n",
      "F1: 0.1731\n",
      "Presision: 0.3193\n",
      "Recall: 0.1187\n",
      "Lift : 4.29\n"
     ]
    }
   ],
   "source": [
    "# вручную подберем гиперпараметры модели на кросс-валидации\n",
    "predictors = [x for x in train.columns if x not in [target, IDcol]]\n",
    "\n",
    "xgb1 = XGBClassifier(learning_rate =0.01, n_estimators=2000, max_depth=2, min_child_weight=1,\n",
    "                     gamma=0, subsample=0.9, colsample_bytree=0.68, reg_alpha=0,\n",
    "                     objective= 'binary:logistic', nthread=4, scale_pos_weight=4, seed=27)\n",
    "modelfit(xgb1, train, predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.9167\n",
      "PR-AUC: 0.1019\n",
      "ROC-AUC: 0.7347\n",
      "F1: 0.164\n",
      "Presision: 0.3245\n",
      "Recall: 0.1097\n",
      "Lift : 4.361\n"
     ]
    }
   ],
   "source": [
    "# исключим из выборки признаки, имеющие низкую корреляцию с целевой переменной (из задания первой недели)\n",
    "predictors = [x for x in train.columns if x not in [target, IDcol, 'Var198', 'Var220', 'Var133', 'Var140', 'Var32',\n",
    "                                                    'Var39', 'Var15', 'Var8', 'Var48', 'Var141', 'Var20', 'Var31',\n",
    "                                                    'Var42', 'Var52', 'Var55', 'Var79', 'Var167']]\n",
    "\n",
    "xgb2 = XGBClassifier(learning_rate =0.01, n_estimators=2000, max_depth=2, min_child_weight=1,\n",
    "                     gamma=0, subsample=0.9, colsample_bytree=0.68, reg_alpha=0,\n",
    "                     objective= 'binary:logistic', nthread=4, scale_pos_weight=4, seed=27)\n",
    "modelfit(xgb2, train, predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сформируем submission на kaggle\n",
    "preds = xgb2.predict_proba(df_test[predictors])\n",
    "preds = pd.DataFrame(preds[:,1], columns=['result'])\n",
    "preds.to_csv(\"sub2.csv\", index=True, index_label='Id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](kaggle.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

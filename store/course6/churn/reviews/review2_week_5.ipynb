{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Peer-graded Assignment: Эксперименты с моделью\n",
    "\n",
    "На прошлой неделе вы поучаствовали в соревновании на kaggle и, наверняка, большинство успешно справилось с прохождением baseline, а значит пора двигаться дальше - заняться оптимизацией модели, провести серию экспериментов и построить сильное финальное решения.\n",
    "\n",
    "В этом задании вам нужно провести ряд эскпериментов, оценить качество полученных в процессе экспериментирования моделей и выбрать лучшее решение. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание будет оцениваться на основании загруженного jupyther notebook и развернутых ответов на поставленные вопросы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, StratifiedKFold\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_extraction import FeatureHasher\n",
    "\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "from imblearn.under_sampling import ClusterCentroids\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# загрузка данных \n",
    "\n",
    "def read_df_from_csv():\n",
    "    '''читаем данные из CSV файла'''\n",
    "    \n",
    "    churn_data_df = pd.read_csv('orange_small_churn_data.txt', sep=',')\n",
    "    labels_df = pd.read_csv('orange_small_churn_labels.txt', sep=',', names=['label'])\n",
    "    labels_df['target'] = labels_df.label == 1\n",
    "    labels_df = labels_df.drop(['label'], axis=1)\n",
    "    full_df = pd.concat([churn_data_df, labels_df], axis=1, sort=False)\n",
    "    return full_df\n",
    "\n",
    "def sample_prepare(data_df, unimportant_features = []):\n",
    "    '''готовим выборку'''\n",
    "    \n",
    "    labels_df = data_df[['target']]\n",
    "    data_df = data_df.drop(['target'], axis=1)\n",
    "    \n",
    "    columns = data_df.columns\n",
    "    columns_numbers = data_df.columns[:190]\n",
    "    columns_cat = data_df.columns[-40:]\n",
    "\n",
    "    # удаляем признаки не содержащине данных \n",
    "    empty_columns = []\n",
    "\n",
    "    for col_name in columns:\n",
    "        # проверям, что вообще нет данных \n",
    "        if len(data_df[col_name].value_counts()) == 0: \n",
    "           empty_columns.append(col_name) \n",
    "        \n",
    "    empty_columns += unimportant_features\n",
    "\n",
    "    columns_numbers = [x for x in columns_numbers if x not in empty_columns]\n",
    "    columns_cat = [x for x in columns_cat if x not in empty_columns]\n",
    "\n",
    "    data_without_nulls = data_df[[x for x in columns if x not in empty_columns]]\n",
    "\n",
    "    # разные выборки для обучения и валидации\n",
    "    X, X_hold_out, y, y_hold_out = train_test_split(data_without_nulls, labels_df.target, test_size=0.1, random_state=42)\n",
    "    _, X_small, _, y_small = train_test_split(X, y, test_size=0.4, random_state=42)  # сокращенная выборка для быстрой проверки\n",
    "    \n",
    "    Xy = pd.concat([X, pd.DataFrame(y)], axis=1, sort=False)  # выборка с признаками и целевой переменной\n",
    "    Xy_calss0 = Xy[Xy.target == 0]\n",
    "    Xy_calss1 = Xy[Xy.target == 1]\n",
    "\n",
    "    \n",
    "    return (X, y, X_small, y_small, X_hold_out, y_hold_out, \n",
    "            columns, columns_numbers, columns_cat,\n",
    "            Xy, Xy_calss0, Xy_calss1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер hold out выборки: (4000, 212)\n",
      "Размер основной выборки: (36000, 212)\n",
      "Размер сокращенной выборки: (14400, 212)\n"
     ]
    }
   ],
   "source": [
    "full_df = read_df_from_csv()\n",
    "\n",
    "(X, y, X_small, y_small, X_hold_out, y_hold_out, \n",
    "    columns, columns_numbers, columns_cat,\n",
    "    Xy, Xy_calss0, Xy_calss1) = sample_prepare(full_df)\n",
    "\n",
    "print \"Размер hold out выборки: {}\".format(X_hold_out.shape)\n",
    "print \"Размер основной выборки: {}\".format(X.shape)\n",
    "print \"Размер сокращенной выборки: {}\".format(X_small.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline\n",
    "\n",
    "def set_cat_features_lists(threshold):\n",
    "    '''разбивает категориальные признаки на группы'''\n",
    "    \n",
    "    columns_with_uniq_values = {}\n",
    "    for col_name in columns_cat:\n",
    "        columns_with_uniq_values[col_name] = (\n",
    "            len(full_df[col_name].value_counts()), \n",
    "            (full_df[col_name].notnull()).sum()\n",
    "        )\n",
    "\n",
    "    ordered = OrderedDict(sorted(columns_with_uniq_values.items(), key=lambda t: t[1][0]))\n",
    "\n",
    "    global columns_cat_for_one_hot_encoding\n",
    "    global columns_cat_for_trick\n",
    "\n",
    "    columns_cat_for_one_hot_encoding = [k for k, v in columns_with_uniq_values.iteritems() if v[0] <= threshold] \n",
    "    columns_cat_for_trick = [k for k, v in columns_with_uniq_values.iteritems() if v[0] > threshold]\n",
    "    \n",
    "def fit_vectorizers(X):\n",
    "    '''обучает векторайзеры'''\n",
    "    \n",
    "    vectorizer_ohe = DictVectorizer(sparse=False)\n",
    "    vectorizer_trick = DictVectorizer(sparse=False)\n",
    "    \n",
    "    vectorizer_ohe.fit(X[columns_cat_for_one_hot_encoding].fillna('no_data').to_dict('records'))\n",
    "\n",
    "    data_cat_for_trick = X[columns_cat_for_trick].fillna('no_data').copy()\n",
    "    for col_name in columns_cat_for_trick:\n",
    "        top_values = list(data_cat_for_trick[col_name].value_counts()[:25].index)\n",
    "        data_cat_for_trick[col_name] = data_cat_for_trick[col_name].apply(lambda x: x if x in top_values else 'rare')\n",
    "\n",
    "    vectorizer_trick.fit(data_cat_for_trick.to_dict('records'))\n",
    "\n",
    "    return vectorizer_ohe, vectorizer_trick\n",
    "\n",
    "def fit_positive_probability_for_cat_values(X, y):\n",
    "    '''веротяность появления значения признака'''\n",
    "    \n",
    "    X_without_nulls = X[columns_cat_for_trick].fillna('no_data')\n",
    "    results = {}\n",
    "    \n",
    "    for col_name in columns_cat_for_trick:\n",
    "        all_values = X_without_nulls[col_name].value_counts()\n",
    "        positive_values = X_without_nulls[col_name][y==1].value_counts()\n",
    "        values = {}\n",
    "        for v in all_values.index:\n",
    "            if all_values[v] > 100 and v in positive_values.index:\n",
    "                values[v] = positive_values[v] / float(all_values[v])\n",
    "        results[col_name] = values\n",
    "        \n",
    "    return results\n",
    "\n",
    "class OneHotEncoding(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, vectorizer):\n",
    "        self.vectorizer = vectorizer\n",
    "    \n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, data_dict):\n",
    "        return vectorizer_ohe.transform(data_dict.fillna('no_data').to_dict('records'))\n",
    "    \n",
    "class PositiveProbabilityEncoder(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, data_dict):\n",
    "        \n",
    "        result = None\n",
    "        for col_name in data_dict.columns:\n",
    "            r = data_dict[col_name].fillna('no_data').apply(lambda x: \n",
    "                positive_probability_values[col_name][x] if x in positive_probability_values[col_name] else 0).values\n",
    "            \n",
    "            r = r.reshape(len(r),1)\n",
    "            if result is not None:\n",
    "                result = np.hstack((result, r))\n",
    "            else:\n",
    "                result = r        \n",
    "        \n",
    "        return result\n",
    "    \n",
    "class HashingTrickEncoder(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, one_vector_for_one_column=True):\n",
    "        self.one_vector_for_one_column = one_vector_for_one_column\n",
    "    \n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, data_dict):\n",
    "\n",
    "        hasher = FeatureHasher(n_features=8, input_type='string')\n",
    "        \n",
    "        if self.one_vector_for_one_column:\n",
    "            result = None\n",
    "            for col_name in data_dict.columns:\n",
    "                r = hasher.transform(data_dict[col_name].fillna('no_data')).toarray()\n",
    "                if result is not None:\n",
    "                    result = np.hstack((result, r))\n",
    "                else:\n",
    "                    result = r        \n",
    "\n",
    "            return result\n",
    "        else:\n",
    "            return hasher.transform(data_dict.fillna('no_data').to_dict('records')).toarray()\n",
    "        \n",
    "def get_classifier(class_weight=1, xgb_params={}):\n",
    "    ''' классификатор'''\n",
    "    \n",
    "    xgb = XGBClassifier(**xgb_params)\n",
    "    xgb.scale_pos_weight = class_weight\n",
    "    \n",
    "    return xgb\n",
    "\n",
    "def make_pl(X, y, enabled_transformers = None, class_weight=1, xgb_params={}):\n",
    "    ''' формируем пайплайн '''\n",
    "    \n",
    "    global vectorizer_ohe\n",
    "    global vectorizer_trick\n",
    "    global positive_probability_values\n",
    "    global features_names\n",
    "    \n",
    "    if enabled_transformers is None:\n",
    "        enabled_transformers = ['cats_ohe', 'cats_ohe_trick', 'cats_positive_probability', 'cats_hashing_trick']\n",
    "    \n",
    "    set_cat_features_lists(25)\n",
    "    vectorizer_ohe, vectorizer_trick = fit_vectorizers(X)\n",
    "    positive_probability_values = fit_positive_probability_for_cat_values(X, y)   \n",
    "    \n",
    "    \n",
    "    transformer_list=[]\n",
    "    transformer_list.append(\n",
    "            ('nums', Pipeline([\n",
    "                    ('selector', FunctionTransformer(lambda X: X[columns_numbers].values, validate=0)),\n",
    "                    ('num_fill_zeros', Imputer(missing_values='NaN', strategy='mean', axis=0)),\n",
    "                ])))\n",
    "    \n",
    "    if 'cats_ohe' in enabled_transformers:\n",
    "        transformer_list.append(\n",
    "            ('cats_ohe', Pipeline([\n",
    "                    ('selector', FunctionTransformer(lambda X: X[columns_cat_for_one_hot_encoding], validate=0)),\n",
    "                    ('ohe_vecrorizer', OneHotEncoding(vectorizer_ohe)),\n",
    "                ])))\n",
    "\n",
    "    if 'cats_ohe_trick' in enabled_transformers:    \n",
    "        transformer_list.append(\n",
    "             ('cats_ohe_trick', Pipeline([\n",
    "                    ('selector', FunctionTransformer(lambda X: X[columns_cat_for_trick], validate=0)),\n",
    "                    ('trick', OneHotEncoding(vectorizer_trick))\n",
    "                ])))\n",
    "    \n",
    "    if 'cats_positive_probability' in enabled_transformers:    \n",
    "        transformer_list.append(\n",
    "            ('cats_positive_probability', Pipeline([\n",
    "                    ('selector', FunctionTransformer(lambda X: X[columns_cat_for_trick], validate=0)),\n",
    "                    ('positive_probability', PositiveProbabilityEncoder())\n",
    "                ])))\n",
    "\n",
    "    if 'cats_hashing_trick' in enabled_transformers:        \n",
    "        transformer_list.append(\n",
    "            ('cats_hashing_trick', Pipeline([\n",
    "                    ('selector', FunctionTransformer(lambda X: X[columns_cat_for_trick], validate=0)),\n",
    "                    ('hashing_trick', HashingTrickEncoder(one_vector_for_one_column=False))\n",
    "                ]))\n",
    "    )\n",
    "    \n",
    "    pipeline = Pipeline([\n",
    "         ('union', FeatureUnion(transformer_list)),\n",
    "         ('classifier', get_classifier(class_weight=class_weight, xgb_params=xgb_params))\n",
    "    ])\n",
    "    \n",
    "    features_names = list(columns_numbers)  # названия числовых признаков \n",
    "    if 'cats_ohe' in enabled_transformers:\n",
    "        features_names += vectorizer_ohe.get_feature_names()  # названия для OHE\n",
    "        \n",
    "    if 'cats_ohe_trick' in enabled_transformers:\n",
    "        features_names += vectorizer_trick.get_feature_names()  # названия для OHE Trick     \n",
    "        \n",
    "    if 'cats_positive_probability' in enabled_transformers:\n",
    "        features_names += columns_cat_for_trick  # названия для PP        \n",
    "    \n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# валидация \n",
    "\n",
    "def get_score(X, y, enabled_transformers=None, num_fill_zeros__strategy='mean', class_weight=1, without_pl=False, xgb_params={}):\n",
    "    ''' скор на CV '''\n",
    "    \n",
    "    if not without_pl:\n",
    "        model = make_pl(X, y, enabled_transformers=enabled_transformers, class_weight=class_weight, xgb_params=xgb_params)\n",
    "        model.steps[0][1].transformer_list[0][1].set_params(num_fill_zeros__strategy=num_fill_zeros__strategy) \n",
    "    \n",
    "    else:\n",
    "        model = get_classifier(class_weight=class_weight, xgb_params=xgb_params)\n",
    "        \n",
    "    cv = StratifiedKFold(n_splits=3, random_state=1)\n",
    "    return cross_val_score(model, X, y, cv=cv, scoring='roc_auc').mean()\n",
    "\n",
    "def make_prediction(X_train, y_train, X_test, y_test, transformer=None, class_weight_train=1, class_weight_test=1, enabled_transformers=None, xgb_params={}):\n",
    "    ''' скор на отложенной выборке '''\n",
    "\n",
    "    if not transformer:\n",
    "        model = make_pl(X_train, y_train, class_weight=class_weight_train, enabled_transformers=enabled_transformers, xgb_params=xgb_params)\n",
    "        \n",
    "    else:\n",
    "        model = get_classifier(class_weight=class_weight_train, xgb_params=xgb_params)\n",
    "        \n",
    "        X_test = transformer.transform(X_test)\n",
    "        \n",
    "    model.fit(X_train, y_train)\n",
    "    y_predict_proba = model.predict_proba(X_test)\n",
    "    \n",
    "    w = np.array([1]*y_test.shape[0])\n",
    "    w[y_test == 1] = class_weight_test\n",
    "    \n",
    "    return roc_auc_score(y_test, y_predict_proba[:, 1], sample_weight=w)\n",
    "\n",
    "def get_prediction_proba(X_train, y_train, X_test, enabled_transformers=None, xgb_params={}):\n",
    "    \n",
    "    model = make_pl(\n",
    "        X_train, y_train,\n",
    "        enabled_transformers=enabled_transformers, xgb_params=xgb_params)\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    return model.predict_proba(X_test)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline, full sample, roc_auc CV: 0.757796943812\n",
      "baseline, small sample, roc_auc CV: 0.731635505504\n"
     ]
    }
   ],
   "source": [
    "# baseline\n",
    "\n",
    "print \"baseline, full sample, roc_auc CV: {}\".format(get_score(X, y))\n",
    "print \"baseline, small sample, roc_auc CV: {}\".format(get_score(X_small, y_small))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Инструкции"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. Начнем с простого. Давайте оценим как много объектов действительно нужно для построения качественной модели. Для обучения доступна достаточно большая выборка и может так оказаться, что начиная с некоторого момента рост размера обучающей выборки перестает влиять на качество модели. Постройте кривые обучения, обучая модель на выборках разного размера начиная с небольшого количество объектов в обучающей выборке и постепенно наращивая её размер с некоторым шагом. Обратите внимание на `sklearn.model_selection.learning_curve`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve(estimator, title, X, y, ylim=None, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    '''рисует кривую обучения'''\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    \n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, train_sizes=train_sizes, scoring='roc_auc')\n",
    "    \n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    \n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    \n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    \n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Test score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    \n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_learning_curve(make_pl(X, y), 'Churn Prediction Learning Curve', X, y).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Можем использовать сокращенную выборку размером 15к._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. Часто несбалансированные по классам выборки приводят к различным проблемам при обучении моделей. Давайте попробуем по-разному обработать выборку, поиграть с распределением объектов по классам и сделать выводы о том, как соотношение классов влияет на качество модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1\\. Задайте веса объектам так, чтобы соотношение классов с учетом весов объектов изменилось. Попробуйте не менее трёх различных вариантов весов. Меняются ли результаты классификации? Как это сказывается на качестве модели? Какой вариант выглядит наиболее оптимальным с точки зрения качества?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_weight=1, small sample, roc_auc CV: 0.731635505504\n",
      "class_weight=5, small sample, roc_auc CV: 0.727918802837\n",
      "class_weight=12, small sample, roc_auc CV: 0.723844884511\n",
      "class_weight=1, hold out, roc_auc: 0.7484912954\n",
      "class_weight=12, hold out, roc_auc: 0.742011513432\n"
     ]
    }
   ],
   "source": [
    "# меняем веса классов и проверям на CV\n",
    "print \"class_weight=1, small sample, roc_auc CV: {}\".format(get_score(X_small, y_small))\n",
    "print \"class_weight=5, small sample, roc_auc CV: {}\".format(get_score(X_small, y_small, class_weight=5))\n",
    "print \"class_weight=12, small sample, roc_auc CV: {}\".format(get_score(X_small, y_small, class_weight=12))\n",
    "\n",
    "# проверим, на hold out выборке\n",
    "print \"class_weight=1, hold out, roc_auc: {}\".format(make_prediction(X, y, X_hold_out, y_hold_out, class_weight_train=1, class_weight_test=1))\n",
    "print \"class_weight=12, hold out, roc_auc: {}\".format(make_prediction(X, y, X_hold_out, y_hold_out, class_weight_train=12, class_weight_test=12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Выглядит так, что добавления весов объектам разных классов не оказывают положительного влияния на скор._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2\\. Примените к выборке технологию undersampling: для этого нужно убрать из обучения некоторое количество объектов большего класса таким образом, чтобы соотношение классов изменилось. Попробуйте не менее трёх различных вариантов undersampling (варианты могут отличаться как по количество отфильтрованных объектов, так и по принципу выборка объектов для отсеивания из выборки). Меняются ли результаты классификации? Как это сказывается на качестве модели? Какой вариант выглядит наиболее оптимальным с точки зрения качества?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = make_pl(X, y).steps[:-1][0][1]\n",
    "X_transformed = transformer.fit_transform(X)  # трансформированные данные "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random undersampling, full sample, roc_auc CV: 0.724910298812\n",
      "random undersampling, hold out, roc_auc: 0.736070989071\n"
     ]
    }
   ],
   "source": [
    "# random undersampling\n",
    "Xy_calss0_under = Xy_calss0.sample(len(Xy_calss1))\n",
    "Xy_random_undersampling = pd.concat([Xy_calss0_under, Xy_calss1], axis=0)\n",
    "\n",
    "X_random_undersampling = Xy_random_undersampling.drop(['target'], axis=1)\n",
    "y_random_undersampling = Xy_random_undersampling.target\n",
    "\n",
    "print \"random undersampling, full sample, roc_auc CV: {}\".format(get_score(X_random_undersampling, y_random_undersampling))\n",
    "print \"random undersampling, hold out, roc_auc: {}\".format(make_prediction(X_random_undersampling, y_random_undersampling, X_hold_out, y_hold_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random oversampling, full sample, roc_auc CV: 0.812229171234\n",
      "random oversampling, hold out, roc_auc: 0.734450609044\n"
     ]
    }
   ],
   "source": [
    "# random oversampling\n",
    "Xy_calss1_over = Xy_calss1.sample(len(Xy_calss0), replace=True)\n",
    "Xy_random_oversampling = pd.concat([Xy_calss0, Xy_calss1_over], axis=0)\n",
    "\n",
    "X_random_oversampling = Xy_random_oversampling.drop(['target'], axis=1)\n",
    "y_random_oversampling = Xy_random_oversampling.target\n",
    "\n",
    "print \"random oversampling, full sample, roc_auc CV: {}\".format(get_score(X_random_oversampling, y_random_oversampling))\n",
    "print \"random oversampling, hold out, roc_auc: {}\".format(make_prediction(X_random_oversampling, y_random_oversampling, X_hold_out, y_hold_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tomek links, full sample, roc_auc CV: 0.757723488049\n",
      "Tomek links, hold out, roc_auc: 0.709541339897\n"
     ]
    }
   ],
   "source": [
    "# Under-sampling: Tomek links\n",
    "tl = TomekLinks(random_state=42)\n",
    "X_tl, y_tl = tl.fit_sample(X_transformed, y)\n",
    "\n",
    "print \"Tomek links, full sample, roc_auc CV: {}\".format(get_score(X_tl, y_tl, without_pl=1))\n",
    "print \"Tomek links, hold out, roc_auc: {}\".format(make_prediction(X_tl, y_tl, X_hold_out, y_hold_out, transformer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster Centroids , full sample, roc_auc CV: 0.991555744934\n",
      "Cluster Centroids , hold out, roc_auc: 0.61356434938\n"
     ]
    }
   ],
   "source": [
    "# Under-sampling: Cluster Centroids \n",
    "cc = ClusterCentroids(random_state=42)\n",
    "X_cc, y_cc = cc.fit_sample(X_transformed, y)\n",
    "\n",
    "print \"Cluster Centroids , full sample, roc_auc CV: {}\".format(get_score(X_cc, y_cc, without_pl=1))\n",
    "print \"Cluster Centroids , hold out, roc_auc: {}\".format(make_prediction(X_cc, y_cc, X_hold_out, y_hold_out, transformer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE, full sample, roc_auc CV: 0.973802857111\n",
      "SMOTE, hold out, roc_auc: 0.717037064075\n"
     ]
    }
   ],
   "source": [
    "# Over-sampling: SMOTE\n",
    "smote = SMOTE(ratio='minority')\n",
    "X_sm, y_sm = smote.fit_sample(X_transformed, y)\n",
    "\n",
    "print \"SMOTE, full sample, roc_auc CV: {}\".format(get_score(X_sm, y_sm, without_pl=1))\n",
    "print \"SMOTE, hold out, roc_auc: {}\".format(make_prediction(X_sm, y_sm, X_hold_out, y_hold_out, transformer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Применение undersampling/oversampling не оказывает положительного влияния на скор модели._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. Теперь перейдем к работе с признаками. Ранее вы реализовали несколько стратегий для обработки пропущенных значений. Сравните эти стратегии между собой с помощью оценки качества моделей кросс-валидации, построенных на датасетах с использованием различных стратегий. Как обработка пропущенных значений сказывается на качестве модели? Какой вариант выглядит наиболее оптимальным с точки зрения качества?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean, small sample, roc_auc CV: 0.731635505504\n",
      "median, small sample, roc_auc CV: 0.72335791986\n",
      "most_frequent, small sample, roc_auc CV: 0.725678296123\n"
     ]
    }
   ],
   "source": [
    "print \"mean, small sample, roc_auc CV: {}\".format(get_score(X_small, y_small, num_fill_zeros__strategy='mean'))\n",
    "print \"median, small sample, roc_auc CV: {}\".format(get_score(X_small, y_small, num_fill_zeros__strategy='median'))\n",
    "print \"most_frequent, small sample, roc_auc CV: {}\".format(get_score(X_small, y_small, num_fill_zeros__strategy='most_frequent'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Наиболее эффективным является замена пропусков средним значением._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\\. Также вы уже реализовали несколько стратегий для обработки категориальных признаков. Сравните эти стратегии между собой с помощью оценки качества моделей по кросс-валидации, построенных на датасетах с использованием различных стратегий. Как обработка категориальных признаков сказывается на качестве модели? Какой вариант выглядит наиболее оптимальным с точки зрения качества?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no cat, small sample, roc_auc CV: 0.71319805046\n",
      "ohe, small sample, roc_auc CV: 0.727334970504\n",
      "ohe|ohe_trick, small sample, roc_auc CV: 0.727334970504\n",
      "ohe|ohe_trick|positive_probability, small sample, roc_auc CV: 0.731635505504\n",
      "ohe|ohe_trick|positive_probability|hashing_trick, small sample, roc_auc CV: 0.731635505504\n",
      "positive_probability|hashing_trick, small sample, roc_auc CV: 0.7286151503\n",
      "ohe|positive_probability, small sample, roc_auc CV: 0.731635505504\n"
     ]
    }
   ],
   "source": [
    "print \"no cat, small sample, roc_auc CV: {}\".format(get_score(X_small, y_small, enabled_transformers = []))\n",
    "print \"ohe, small sample, roc_auc CV: {}\".format(get_score(X_small, y_small, enabled_transformers = ['cats_ohe']))\n",
    "print \"ohe|ohe_trick, small sample, roc_auc CV: {}\".format(get_score(X_small, y_small, enabled_transformers = ['cats_ohe', 'cats_ohe_trick']))\n",
    "print \"ohe|ohe_trick|positive_probability, small sample, roc_auc CV: {}\".format(get_score(X_small, y_small, enabled_transformers = ['cats_ohe', 'cats_ohe_trick', 'cats_positive_probability']))\n",
    "print \"ohe|ohe_trick|positive_probability|hashing_trick, small sample, roc_auc CV: {}\".format(get_score(X_small, y_small, enabled_transformers = ['cats_ohe', 'cats_ohe_trick', 'cats_positive_probability', 'cats_hashing_trick']))\n",
    "print \"positive_probability|hashing_trick, small sample, roc_auc CV: {}\".format(get_score(X_small, y_small, enabled_transformers = ['cats_positive_probability', 'cats_hashing_trick']))\n",
    "print \"ohe|positive_probability, small sample, roc_auc CV: {}\".format(get_score(X_small, y_small, enabled_transformers = ['cats_ohe', 'cats_positive_probability']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Будем использовать: OneHotEncoding, замена значения вероятностью позитивного класса_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5\\. Все ли признаки оказались полезными для построения моделей? Проведите процедуру отбора признаков, попробуйте разные варианты отбора (обратите внимание на модуль `sklearn.feature_selection`). Например, можно выбрасывать случайные признаки или строить отбор на основе l1-регуляризации - отфильтровать из обучения признаки, которые получат нулевой вес при построении регрессии с l1-регуляризацией (`sklearn.linear_model.Lasso`). И всегда можно придумать что-то своё=) Попробуйте как минимум 2 различные стратегии, сравните результаты. Помог ли отбор признаков улучшить качество модели? Поясните свой ответ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_importances(X, y):\n",
    "    ''' возвращает признаки + значимость '''\n",
    "    pl = make_pl(X, y, enabled_transformers = ['cats_ohe', 'cats_positive_probability'])\n",
    "    X_transformed = pl.steps[:-1][0][1].fit_transform(X)  # трансформированные данные \n",
    "    model = get_classifier().fit(X_transformed, y)\n",
    "    \n",
    "    feature_importances = model.feature_importances_\n",
    "    thresholds = sort(list(set(feature_importances)))\n",
    "    return model, X_transformed, zip(features_names, feature_importances), thresholds\n",
    "\n",
    "def get_score_with_diff_features(thresholds, model, X_transformed):\n",
    "    ''' скор модели в зависимости от кол-ва признаков '''\n",
    "    \n",
    "    for thresh in thresholds:\n",
    "        X_selected = SelectFromModel(model, threshold=thresh, prefit=True).transform(X_transformed)\n",
    "\n",
    "        cv = StratifiedKFold(n_splits=3, random_state=1)\n",
    "        score = cross_val_score(get_classifier(), X_selected, y_small, cv=cv, scoring='roc_auc')\n",
    "        print \"Thresh={}, n = {}, roc_auc = {}\".format(thresh, X_selected.shape[1], score.mean())    \n",
    "        \n",
    "def get_unimportant_features(feature_importances, threshold):\n",
    "    ''' формирует списки не важных признаков'''\n",
    "    \n",
    "    unimportant_features = [t[0] for t in feature_importances if t[1] < threshold]\n",
    "    unimportant_features_numbers = list(set(unimportant_features).intersection(columns_numbers))\n",
    "    unimportant_features_cat = list(set(unimportant_features).intersection(columns_cat))\n",
    "    \n",
    "    for col_name in columns_cat:\n",
    "        l1 = len([t[0] for t in feature_importances if t[0].startswith(col_name + '=')])\n",
    "        l2 = len(full_df[col_name].value_counts())\n",
    "        if l1 == l2:\n",
    "            unimportant_features_cat.append(col_name)\n",
    "\n",
    "    return unimportant_features_numbers #+ unimportant_features_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# получаем список важности признаков от XGBoost\n",
    "model, X_trans, feature_importances, thresholds = get_feature_importances(X_small, y_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thresh=0.0, n = 357, roc_auc = 0.731352111008\n",
      "Thresh=0.00154320988804, n = 91, roc_auc = 0.733691197531\n",
      "Thresh=0.00308641977608, n = 62, roc_auc = 0.736527435857\n",
      "Thresh=0.00462962966412, n = 56, roc_auc = 0.736491190876\n",
      "Thresh=0.00617283955216, n = 45, roc_auc = 0.73418780159\n",
      "Thresh=0.00771604944021, n = 39, roc_auc = 0.734664422738\n",
      "Thresh=0.00925925932825, n = 33, roc_auc = 0.734799482045\n",
      "Thresh=0.0108024692163, n = 28, roc_auc = 0.735629670148\n",
      "Thresh=0.0123456791043, n = 25, roc_auc = 0.737809940128\n",
      "Thresh=0.0138888889924, n = 22, roc_auc = 0.737484943199\n",
      "Thresh=0.0154320988804, n = 18, roc_auc = 0.737479436485\n",
      "Thresh=0.0185185186565, n = 17, roc_auc = 0.738213015725\n",
      "Thresh=0.0200617276132, n = 16, roc_auc = 0.739998048251\n",
      "Thresh=0.0231481473893, n = 15, roc_auc = 0.739576371218\n",
      "Thresh=0.0246913582087, n = 12, roc_auc = 0.739265920648\n",
      "Thresh=0.0262345671654, n = 9, roc_auc = 0.737142359283\n",
      "Thresh=0.0293209869415, n = 8, roc_auc = 0.727991596323\n",
      "Thresh=0.0324074067175, n = 7, roc_auc = 0.727924649346\n",
      "Thresh=0.037037037313, n = 5, roc_auc = 0.717381737291\n",
      "Thresh=0.0432098768651, n = 4, roc_auc = 0.703567737393\n",
      "Thresh=0.0524691343307, n = 3, roc_auc = 0.697791435106\n",
      "Thresh=0.0663580223918, n = 2, roc_auc = 0.682118473041\n",
      "Thresh=0.114197529852, n = 1, roc_auc = 0.667378555778\n"
     ]
    }
   ],
   "source": [
    "# смотрим, как влияет кол-во признаков на скор \n",
    "get_score_with_diff_features(thresholds, model, X_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# формируем список не важных признаков \n",
    "unimportant_features = get_unimportant_features(feature_importances, 0.020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# формируем выборку без \"плохих\" признаков\n",
    "(X, y, X_small, y_small, X_hold_out, y_hold_out, \n",
    "    columns, columns_numbers, columns_cat,\n",
    "    Xy, Xy_calss0, Xy_calss1) = sample_prepare(full_df, unimportant_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected features, small sample, roc_auc CV: 0.7424946181\n",
      "selected features, full sample, roc_auc CV: 0.758202907957\n"
     ]
    }
   ],
   "source": [
    "print \"selected features, small sample, roc_auc CV: {}\".format(get_score(X_small, y_small, enabled_transformers = ['cats_ohe', 'cats_positive_probability']))\n",
    "print \"selected features, full sample, roc_auc CV: {}\".format(get_score(X, y, enabled_transformers = ['cats_ohe', 'cats_positive_probability']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Отбор признаков улучшил качество модели и ускорил обучение._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6\\. Подберите оптимальные параметры модели. Обратите внимание, что в зависимости от того, как вы обработали исходные данные, сделали ли балансировку классов, сколько объектов оставили в обучающей выборке и др. оптимальные значения параметров могут меняться. Возьмите наилучшее из ваших решений на текущий момент и проведите процедуру подбора параметров модели (обратите внимание на `sklearn.model_selection.GridSearchCV`) Как подбор параметров повлиял на качество модели?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pl = make_pl(X_small, y_small, enabled_transformers = ['cats_ohe', 'cats_positive_probability'])\n",
    "\n",
    "params = {\n",
    "        'classifier__min_child_weight': [1, 5, 10],\n",
    "        'classifier__gamma': [7, 8, 9],\n",
    "        'classifier__subsample': [0.5, 0.6, 0.8],\n",
    "        'classifier__colsample_bytree': [0.5, 0.6, 0.8],\n",
    "        'classifier__n_estimators': [30, 50, 100, 150],\n",
    "        'classifier__max_depth': [1, 2, 3, 4]\n",
    "        }\n",
    "\n",
    "search_clf = GridSearchCV(pl, params, scoring='roc_auc')\n",
    "search_clf.fit(X_small, y_small)\n",
    "search_clf.best_score_, search_clf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Подбор гиперпараметров улучшил качество модели._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7\\. Предложите методику оценки того, какие признаки внесли наибольший вклад в модель (например, это могут быть веса в случае регрессии, а также большое количество моделей реализуют метод `feature_importances_` - оценка важности признаков). На основе предложенной методики проанализируйте, какие признаки внесли больший вклад в модель, а какие меньший?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Топ 10 важных признаков: Var228, Var73, Var199, Var81, Var218=no_data, Var74, Var204, Var189, Var113, Var126\n",
      "\n",
      "Не важные признаки: Var2, Var3, Var4, Var5, Var7, Var9, Var10, Var11, Var12, Var14, Var17, Var18, Var19, Var23, Var24, Var26, Var27, Var29, Var30, Var33, Var34, Var36, Var37, Var40, Var41, Var43, Var44, Var45, Var46, Var47, Var49, Var51, Var53, Var54, Var58, Var59, Var60, Var62, Var63, Var64, Var66, Var67, Var68, Var70, Var75, Var77, Var78, Var80, Var82, Var84, Var87, Var88, Var89, Var90, Var91, Var93, Var95, Var96, Var97, Var99, Var100, Var101, Var103, Var104, Var105, Var106, Var107, Var108, Var110, Var115, Var116, Var117, Var118, Var120, Var121, Var122, Var124, Var127, Var128, Var129, Var130, Var131, Var135, Var136, Var137, Var138, Var139, Var142, Var143, Var144, Var145, Var146, Var147, Var148, Var151, Var152, Var155, Var156, Var157, Var161, Var162, Var164, Var165, Var166, Var168, Var170, Var171, Var172, Var173, Var174, Var176, Var177, Var178, Var179, Var180, Var182, Var183, Var184, Var186, Var187, Var190, Var191=no_data, Var191=r__I, Var194=CTUH, Var194=SEuy, Var194=lvza, Var195=ArtjQZ8ftr3NB, Var195=ArtjQZQO1r9fC, Var195=ArtjQZmIvr94p, Var195=BNjsq81k1tWAYigY, Var195=CiJDdr4TQ0rGERIS, Var195=CiJsoa4TQ0rGHlMp, Var195=CuXi4je, Var195=F1JQrEL, Var195=I9xt3GBDKUbd8, Var195=I9xt3GDRhUK7p, Var195=I9xt3GMcxUnBZ, Var195=I9xt3Gi01UK7p, Var195=LfvqpCtLOY, Var195=TnJpfvsJgF, Var195=V10_0kx3ZF2we, Var195=ZZBPiZh, Var195=b_3Q, Var195=bsZtYxFjzA, Var195=ev6I, Var195=hiMqnEM7VgIk4JUu, Var195=lSbpiq1, Var196=1K8T, Var196=JA1C, Var196=z3mO, Var201=6dX3, Var201=no_data, Var201=smXZ, Var203=9_Y1, Var203=F3hy, Var203=dgxZ, Var203=no_data, Var205=09_Q, Var206=409L, Var206=43pnToF, Var206=69fI, Var206=6JmL, Var206=CoYW, Var206=G_zk, Var206=TIA9, Var206=Tkho, Var206=giwq, Var206=haYg, Var206=hzlB, Var206=itlM, Var206=kxE9, Var206=oZyB, Var206=sYC_, Var206=y6dw, Var207=0MCPoln, Var207=15TtzZrRt2, Var207=5iay, Var207=6C53VA1kCv, Var207=7M47J5GA0pTYIFxg5uy, Var207=DHn_WUyBhW_whjA88g9bvA64_, Var207=EBKcR3s6B22tD6gC36gm6S, Var207=GjJ35utlTa_GNSvxxpb9ju, Var207=Kxdu, Var207=NKv3VA1BpP, Var207=me75fM6ugJ, Var207=o0ZZAVSQ32YuE, Var207=tMBVJkA0xJMEATvl4ht, Var207=wXfldy7, Var208=no_data, Var208=sBgB, Var210=3av_, Var210=7A3j, Var210=DM_V, Var211=L84s, Var211=Mtgm, Var213=KdSa, Var213=no_data, Var215=eGzu, Var215=no_data, Var219=AT1N, Var219=AU8KzzF, Var219=AU8_WTd, Var219=AU8ltHK, Var219=AU8pNoi, Var219=FQHxeR8, Var219=FqMWi1g, Var219=HEoH, Var219=JdAM, Var219=Lmli, Var219=OFWH, Var219=lkwAXjv, Var219=no_data, Var219=qxDb, Var219=tdJW_Pm, Var219=ylgWTXl, Var221=Al6ZaUT, Var221=JIiEFBU, Var221=QKW8DRm, Var221=oslk, Var221=z4pH, Var221=zCkv, Var223=LM8l689qOp, Var223=M_8D, Var223=bCPvVye, Var223=jySVZNlOJy, Var223=no_data, Var224=4n2X, Var224=no_data, Var225=xG3x, Var226=3Cy4, Var226=453m, Var226=5Acm, Var226=7FJQ, Var226=7P5s, Var226=7aLG, Var226=Aoh3, Var226=PM2D, Var226=Qcbd, Var226=Qu4f, Var226=WqMG, Var226=kwS7, Var226=me1d, Var226=rgKb, Var226=szEZ, Var226=uWr3, Var226=wX53, Var226=w_Ub, Var226=xb3V, Var227=6fzt, Var227=RAYp, Var227=ZI9m, Var227=nIGXDli, Var227=nIGjgSB, Var227=vJ_w8kB, Var229=am7c, Var229=mj86, Var229=no_data, Var229=oJmt, Var229=sk2h, Var193, Var220, Var200, Var202, Var217, Var214, Var198\n"
     ]
    }
   ],
   "source": [
    "feature_importances_sorted = sorted(feature_importances, key=lambda tup: tup[1])\n",
    "\n",
    "print 'Топ 10 важных признаков: ' + ', '.join([t[0] for t in feature_importances_sorted[-10:]])\n",
    "print \n",
    "print 'Не важные признаки: ' + ', '.join([t[0] for t in feature_importances if t[1] == 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8\\. Напоследок давайте посмотрим на объекты. На каких объектах достигается наибольшая ошибка классификации? Есть ли межу этими объектами что-то общее? Видны ли какие-либо закономерности? Предположите, почему наибольшая ошибка достигается именно на этих объектах. В данном случае \"наибольшую\" ошибку можно понимать как отнесение объекта с чужому классу с большой долей уверенности (с высокой вероятностью)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_proba = get_prediction_proba(X, y, X_hold_out, \n",
    "         enabled_transformers = ['cats_ohe', 'cats_positive_probability'], xgb_params=classifier_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14400561\n",
      "0.0678166\n"
     ]
    }
   ],
   "source": [
    "print y_predict_proba[:, 1][y_hold_out.values == 1].mean()\n",
    "print y_predict_proba[:, 1][y_hold_out.values == 0].mean()\n",
    "top_features = ['Var228', 'Var73', 'Var199', 'Var81', 'Var218', 'Var74', 'Var204', 'Var189', 'Var113', 'Var126']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 72\n"
     ]
    }
   ],
   "source": [
    "false_positive = X_hold_out[(y_hold_out.values == 1) & (y_predict_proba[:, 1] <= 0.04)][top_features]\n",
    "true_positive = X_hold_out[(y_hold_out.values == 1) & (y_predict_proba[:, 1] > 0.2)][top_features]\n",
    "print len(false_positive), len(true_positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Var228</th>\n",
       "      <th>Var73</th>\n",
       "      <th>Var199</th>\n",
       "      <th>Var81</th>\n",
       "      <th>Var218</th>\n",
       "      <th>Var74</th>\n",
       "      <th>Var204</th>\n",
       "      <th>Var189</th>\n",
       "      <th>Var113</th>\n",
       "      <th>Var126</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4859</th>\n",
       "      <td>TCU50_Yjmm6GIBZ0lL_</td>\n",
       "      <td>174</td>\n",
       "      <td>_jTP8ioIlJ</td>\n",
       "      <td>3815.76</td>\n",
       "      <td>cJvF</td>\n",
       "      <td>28.0</td>\n",
       "      <td>nr0d</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10629.28</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23096</th>\n",
       "      <td>F2FyR07IdsN7I</td>\n",
       "      <td>4</td>\n",
       "      <td>jnKgqlO5Ag</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UYBR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rGJy</td>\n",
       "      <td>210.0</td>\n",
       "      <td>-2946316.00</td>\n",
       "      <td>-20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21124</th>\n",
       "      <td>F2FyR07IdsN7I</td>\n",
       "      <td>38</td>\n",
       "      <td>3X0xOLn</td>\n",
       "      <td>43934.40</td>\n",
       "      <td>cJvF</td>\n",
       "      <td>21.0</td>\n",
       "      <td>lXxA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-805452.00</td>\n",
       "      <td>-20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29842</th>\n",
       "      <td>F2FyR07IdsN7I</td>\n",
       "      <td>40</td>\n",
       "      <td>e1XhvTunuD</td>\n",
       "      <td>214423.20</td>\n",
       "      <td>cJvF</td>\n",
       "      <td>28.0</td>\n",
       "      <td>rzbc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>161273.20</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17496</th>\n",
       "      <td>SbOd7O8ky1wGNxp0Arj0Xs</td>\n",
       "      <td>58</td>\n",
       "      <td>Oe4E7cR6Kt</td>\n",
       "      <td>105731.70</td>\n",
       "      <td>cJvF</td>\n",
       "      <td>35.0</td>\n",
       "      <td>EKFb</td>\n",
       "      <td>216.0</td>\n",
       "      <td>102601.20</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39041</th>\n",
       "      <td>NoEd</td>\n",
       "      <td>214</td>\n",
       "      <td>_jTP8ioIlJ</td>\n",
       "      <td>42865.20</td>\n",
       "      <td>cJvF</td>\n",
       "      <td>0.0</td>\n",
       "      <td>e7QV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>220691.20</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30630</th>\n",
       "      <td>F2FyR07IdsN7I</td>\n",
       "      <td>82</td>\n",
       "      <td>JsluJ5C</td>\n",
       "      <td>70329.30</td>\n",
       "      <td>cJvF</td>\n",
       "      <td>252.0</td>\n",
       "      <td>X8zP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-298746.40</td>\n",
       "      <td>-26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14655</th>\n",
       "      <td>ib5G6X1eUxUn6</td>\n",
       "      <td>158</td>\n",
       "      <td>9YuT4s0Bqf</td>\n",
       "      <td>12634.89</td>\n",
       "      <td>cJvF</td>\n",
       "      <td>231.0</td>\n",
       "      <td>LqKm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-50162.00</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30283</th>\n",
       "      <td>F2FyR07IdsN7I</td>\n",
       "      <td>62</td>\n",
       "      <td>lGXpFd_2Rf</td>\n",
       "      <td>15880.86</td>\n",
       "      <td>UYBR</td>\n",
       "      <td>119.0</td>\n",
       "      <td>t_4G</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1930.00</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2622</th>\n",
       "      <td>ib5G6X1eUxUn6</td>\n",
       "      <td>178</td>\n",
       "      <td>FoJylxy</td>\n",
       "      <td>15298.89</td>\n",
       "      <td>UYBR</td>\n",
       "      <td>287.0</td>\n",
       "      <td>TjV7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-254426.40</td>\n",
       "      <td>58.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Var228  Var73      Var199      Var81 Var218  Var74  \\\n",
       "4859      TCU50_Yjmm6GIBZ0lL_    174  _jTP8ioIlJ    3815.76   cJvF   28.0   \n",
       "23096           F2FyR07IdsN7I      4  jnKgqlO5Ag        NaN   UYBR    NaN   \n",
       "21124           F2FyR07IdsN7I     38     3X0xOLn   43934.40   cJvF   21.0   \n",
       "29842           F2FyR07IdsN7I     40  e1XhvTunuD  214423.20   cJvF   28.0   \n",
       "17496  SbOd7O8ky1wGNxp0Arj0Xs     58  Oe4E7cR6Kt  105731.70   cJvF   35.0   \n",
       "39041                    NoEd    214  _jTP8ioIlJ   42865.20   cJvF    0.0   \n",
       "30630           F2FyR07IdsN7I     82     JsluJ5C   70329.30   cJvF  252.0   \n",
       "14655           ib5G6X1eUxUn6    158  9YuT4s0Bqf   12634.89   cJvF  231.0   \n",
       "30283           F2FyR07IdsN7I     62  lGXpFd_2Rf   15880.86   UYBR  119.0   \n",
       "2622            ib5G6X1eUxUn6    178     FoJylxy   15298.89   UYBR  287.0   \n",
       "\n",
       "      Var204  Var189      Var113  Var126  \n",
       "4859    nr0d     NaN    10629.28     NaN  \n",
       "23096   rGJy   210.0 -2946316.00   -20.0  \n",
       "21124   lXxA     NaN  -805452.00   -20.0  \n",
       "29842   rzbc     NaN   161273.20    16.0  \n",
       "17496   EKFb   216.0   102601.20     4.0  \n",
       "39041   e7QV     NaN   220691.20     4.0  \n",
       "30630   X8zP     NaN  -298746.40   -26.0  \n",
       "14655   LqKm     NaN   -50162.00    32.0  \n",
       "30283   t_4G     NaN    -1930.00    38.0  \n",
       "2622    TjV7     NaN  -254426.40    58.0  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "false_positive.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Var228</th>\n",
       "      <th>Var73</th>\n",
       "      <th>Var199</th>\n",
       "      <th>Var81</th>\n",
       "      <th>Var218</th>\n",
       "      <th>Var74</th>\n",
       "      <th>Var204</th>\n",
       "      <th>Var189</th>\n",
       "      <th>Var113</th>\n",
       "      <th>Var126</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3434</th>\n",
       "      <td>am14IcfM7tWLrUmRT52KtA</td>\n",
       "      <td>42</td>\n",
       "      <td>nQUHwv83X4</td>\n",
       "      <td>47823.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49.0</td>\n",
       "      <td>vzJD</td>\n",
       "      <td>234.0</td>\n",
       "      <td>133014.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26782</th>\n",
       "      <td>F2FyR07IdsN7I</td>\n",
       "      <td>16</td>\n",
       "      <td>ToUSgkq</td>\n",
       "      <td>90967.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>mTeA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-150214.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7656</th>\n",
       "      <td>F2FyR07IdsN7I</td>\n",
       "      <td>56</td>\n",
       "      <td>3cOC7qZ</td>\n",
       "      <td>202095.0</td>\n",
       "      <td>UYBR</td>\n",
       "      <td>560.0</td>\n",
       "      <td>F_Lu</td>\n",
       "      <td>138.0</td>\n",
       "      <td>261366.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14712</th>\n",
       "      <td>SbOd7O8ky1wGNxp0Arj0Xs</td>\n",
       "      <td>86</td>\n",
       "      <td>bAyfFVUl1u</td>\n",
       "      <td>39010.5</td>\n",
       "      <td>UYBR</td>\n",
       "      <td>56.0</td>\n",
       "      <td>rGJy</td>\n",
       "      <td>144.0</td>\n",
       "      <td>60132.0</td>\n",
       "      <td>-8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8054</th>\n",
       "      <td>F2FyR07IdsN7I</td>\n",
       "      <td>12</td>\n",
       "      <td>ZIX6Y9cVy5</td>\n",
       "      <td>226862.4</td>\n",
       "      <td>cJvF</td>\n",
       "      <td>0.0</td>\n",
       "      <td>MBhA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-452788.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16900</th>\n",
       "      <td>F2FyR07IdsN7I</td>\n",
       "      <td>18</td>\n",
       "      <td>BpHkmkQ</td>\n",
       "      <td>126200.4</td>\n",
       "      <td>UYBR</td>\n",
       "      <td>0.0</td>\n",
       "      <td>k13i</td>\n",
       "      <td>120.0</td>\n",
       "      <td>186638.8</td>\n",
       "      <td>-6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34677</th>\n",
       "      <td>F2FyR07IdsN7I</td>\n",
       "      <td>16</td>\n",
       "      <td>0IWZqtp</td>\n",
       "      <td>220283.4</td>\n",
       "      <td>UYBR</td>\n",
       "      <td>0.0</td>\n",
       "      <td>xQ2A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95964.4</td>\n",
       "      <td>-8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38571</th>\n",
       "      <td>F2FyR07IdsN7I</td>\n",
       "      <td>16</td>\n",
       "      <td>fgUKl_eyza</td>\n",
       "      <td>253867.5</td>\n",
       "      <td>UYBR</td>\n",
       "      <td>0.0</td>\n",
       "      <td>mTeA</td>\n",
       "      <td>168.0</td>\n",
       "      <td>-299345.2</td>\n",
       "      <td>-10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30592</th>\n",
       "      <td>F2FyR07IdsN7I</td>\n",
       "      <td>16</td>\n",
       "      <td>AdrCSJ3</td>\n",
       "      <td>204726.9</td>\n",
       "      <td>UYBR</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RVjC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>928520.0</td>\n",
       "      <td>-8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13022</th>\n",
       "      <td>F2FyR07IdsN7I</td>\n",
       "      <td>16</td>\n",
       "      <td>hOpRIhsUSP</td>\n",
       "      <td>165378.3</td>\n",
       "      <td>UYBR</td>\n",
       "      <td>0.0</td>\n",
       "      <td>STGZ</td>\n",
       "      <td>150.0</td>\n",
       "      <td>52466.4</td>\n",
       "      <td>-10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Var228  Var73      Var199     Var81 Var218  Var74  \\\n",
       "3434   am14IcfM7tWLrUmRT52KtA     42  nQUHwv83X4   47823.9    NaN   49.0   \n",
       "26782           F2FyR07IdsN7I     16     ToUSgkq   90967.5    NaN    0.0   \n",
       "7656            F2FyR07IdsN7I     56     3cOC7qZ  202095.0   UYBR  560.0   \n",
       "14712  SbOd7O8ky1wGNxp0Arj0Xs     86  bAyfFVUl1u   39010.5   UYBR   56.0   \n",
       "8054            F2FyR07IdsN7I     12  ZIX6Y9cVy5  226862.4   cJvF    0.0   \n",
       "16900           F2FyR07IdsN7I     18     BpHkmkQ  126200.4   UYBR    0.0   \n",
       "34677           F2FyR07IdsN7I     16     0IWZqtp  220283.4   UYBR    0.0   \n",
       "38571           F2FyR07IdsN7I     16  fgUKl_eyza  253867.5   UYBR    0.0   \n",
       "30592           F2FyR07IdsN7I     16     AdrCSJ3  204726.9   UYBR    0.0   \n",
       "13022           F2FyR07IdsN7I     16  hOpRIhsUSP  165378.3   UYBR    0.0   \n",
       "\n",
       "      Var204  Var189    Var113  Var126  \n",
       "3434    vzJD   234.0  133014.0     NaN  \n",
       "26782   mTeA     NaN -150214.0     4.0  \n",
       "7656    F_Lu   138.0  261366.0     NaN  \n",
       "14712   rGJy   144.0   60132.0    -8.0  \n",
       "8054    MBhA     NaN -452788.0     NaN  \n",
       "16900   k13i   120.0  186638.8    -6.0  \n",
       "34677   xQ2A     NaN   95964.4    -8.0  \n",
       "38571   mTeA   168.0 -299345.2   -10.0  \n",
       "30592   RVjC     NaN  928520.0    -8.0  \n",
       "13022   STGZ   150.0   52466.4   -10.0  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_positive.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Var73</th>\n",
       "      <th>Var81</th>\n",
       "      <th>Var74</th>\n",
       "      <th>Var189</th>\n",
       "      <th>Var113</th>\n",
       "      <th>Var126</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>40.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>4.000000e+01</td>\n",
       "      <td>34.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>87.350000</td>\n",
       "      <td>77273.189647</td>\n",
       "      <td>147.656250</td>\n",
       "      <td>264.800000</td>\n",
       "      <td>-2.243335e+05</td>\n",
       "      <td>1.705882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>68.921937</td>\n",
       "      <td>78063.950136</td>\n",
       "      <td>253.858306</td>\n",
       "      <td>67.459194</td>\n",
       "      <td>8.263466e+05</td>\n",
       "      <td>27.022470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>-2.946316e+06</td>\n",
       "      <td>-30.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>33.500000</td>\n",
       "      <td>13576.972500</td>\n",
       "      <td>12.250000</td>\n",
       "      <td>213.000000</td>\n",
       "      <td>-2.340252e+05</td>\n",
       "      <td>-20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>63.000000</td>\n",
       "      <td>47048.700000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>246.000000</td>\n",
       "      <td>-1.586000e+04</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>134.500000</td>\n",
       "      <td>127106.700000</td>\n",
       "      <td>189.000000</td>\n",
       "      <td>318.000000</td>\n",
       "      <td>1.397089e+05</td>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>244.000000</td>\n",
       "      <td>227069.100000</td>\n",
       "      <td>1204.000000</td>\n",
       "      <td>378.000000</td>\n",
       "      <td>1.709008e+06</td>\n",
       "      <td>64.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Var73          Var81        Var74      Var189        Var113  \\\n",
       "count   40.000000      34.000000    32.000000   15.000000  4.000000e+01   \n",
       "mean    87.350000   77273.189647   147.656250  264.800000 -2.243335e+05   \n",
       "std     68.921937   78063.950136   253.858306   67.459194  8.263466e+05   \n",
       "min      4.000000       0.000000     0.000000  180.000000 -2.946316e+06   \n",
       "25%     33.500000   13576.972500    12.250000  213.000000 -2.340252e+05   \n",
       "50%     63.000000   47048.700000    28.000000  246.000000 -1.586000e+04   \n",
       "75%    134.500000  127106.700000   189.000000  318.000000  1.397089e+05   \n",
       "max    244.000000  227069.100000  1204.000000  378.000000  1.709008e+06   \n",
       "\n",
       "          Var126  \n",
       "count  34.000000  \n",
       "mean    1.705882  \n",
       "std    27.022470  \n",
       "min   -30.000000  \n",
       "25%   -20.000000  \n",
       "50%     4.000000  \n",
       "75%    14.000000  \n",
       "max    64.000000  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "false_positive.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Var73</th>\n",
       "      <th>Var81</th>\n",
       "      <th>Var74</th>\n",
       "      <th>Var189</th>\n",
       "      <th>Var113</th>\n",
       "      <th>Var126</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>72.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>7.200000e+01</td>\n",
       "      <td>45.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>35.805556</td>\n",
       "      <td>138810.717121</td>\n",
       "      <td>21.969231</td>\n",
       "      <td>172.764706</td>\n",
       "      <td>1.680424e+04</td>\n",
       "      <td>-1.911111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>28.252702</td>\n",
       "      <td>93460.942040</td>\n",
       "      <td>94.296237</td>\n",
       "      <td>48.469959</td>\n",
       "      <td>8.459308e+05</td>\n",
       "      <td>12.247119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>-2.992656e+06</td>\n",
       "      <td>-18.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>16.000000</td>\n",
       "      <td>41213.850000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>139.500000</td>\n",
       "      <td>-1.713304e+05</td>\n",
       "      <td>-8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>22.000000</td>\n",
       "      <td>167314.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>156.000000</td>\n",
       "      <td>6.922180e+04</td>\n",
       "      <td>-8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>202302.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>196.500000</td>\n",
       "      <td>3.718698e+05</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>120.000000</td>\n",
       "      <td>340434.000000</td>\n",
       "      <td>560.000000</td>\n",
       "      <td>336.000000</td>\n",
       "      <td>1.895820e+06</td>\n",
       "      <td>38.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Var73          Var81       Var74      Var189        Var113  \\\n",
       "count   72.000000      66.000000   65.000000   34.000000  7.200000e+01   \n",
       "mean    35.805556  138810.717121   21.969231  172.764706  1.680424e+04   \n",
       "std     28.252702   93460.942040   94.296237   48.469959  8.459308e+05   \n",
       "min      6.000000       0.000000    0.000000  120.000000 -2.992656e+06   \n",
       "25%     16.000000   41213.850000    0.000000  139.500000 -1.713304e+05   \n",
       "50%     22.000000  167314.500000    0.000000  156.000000  6.922180e+04   \n",
       "75%     48.000000  202302.900000    0.000000  196.500000  3.718698e+05   \n",
       "max    120.000000  340434.000000  560.000000  336.000000  1.895820e+06   \n",
       "\n",
       "          Var126  \n",
       "count  45.000000  \n",
       "mean   -1.911111  \n",
       "std    12.247119  \n",
       "min   -18.000000  \n",
       "25%    -8.000000  \n",
       "50%    -8.000000  \n",
       "75%     4.000000  \n",
       "max    38.000000  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_positive.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "F2FyR07IdsN7I             21\n",
       "TCU50_Yjmm6GIBZ0lL_        4\n",
       "ib5G6X1eUxUn6              3\n",
       "R4y5gQQWY8OodqDV           2\n",
       "NoEd                       2\n",
       "55YFVY9                    2\n",
       "xwM2aC7IdeMC0              1\n",
       "SbOd7O8ky1wGNxp0Arj0Xs     1\n",
       "WfJ2BB2SFSqauljlfOB        1\n",
       "VjDE                       1\n",
       "iyHGyLCEkQ                 1\n",
       "b9qbUNk0dML_Mvi2           1\n",
       "Name: Var228, dtype: int64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "false_positive['Var228'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "F2FyR07IdsN7I             58\n",
       "SbOd7O8ky1wGNxp0Arj0Xs     4\n",
       "am14IcfM7tWLrUmRT52KtA     3\n",
       "Zy3gnGM                    2\n",
       "R4y5gQQWY8OodqDV           1\n",
       "xwM2aC7IdeMC0              1\n",
       "WfJ2BB2SFSqauljlfOB        1\n",
       "55YFVY9                    1\n",
       "F2FcTt7IdMT_v              1\n",
       "Name: Var228, dtype: int64"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_positive['Var228'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Объекты, на которых ошибается классификатор выглядят, как выбросы._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9\\. По итогам проведенных экспериментов постройте финальную решение - модель с наилучшим качеством. Укажите, какие преобразования данных, параметры и пр. вы выбрали для построения финальной модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuned xgb, small sample, roc_auc CV: 0.744427343912\n",
      "tuned xgb, full sample, roc_auc CV: 0.758385731169\n",
      "tuned xgb, hold out, roc_auc: 0.746695797875\n"
     ]
    }
   ],
   "source": [
    "classifier_params = {'colsample_bytree': 0.5,\n",
    "  'gamma': 8,\n",
    "  'max_depth': 4,\n",
    "  'min_child_weight': 1,\n",
    "  'n_estimators': 150,\n",
    "  'subsample': 0.8}\n",
    "\n",
    "print \"tuned xgb, small sample, roc_auc CV: {}\".format(get_score(X_small, y_small, enabled_transformers = ['cats_ohe', 'cats_positive_probability'], xgb_params=classifier_params))\n",
    "print \"tuned xgb, full sample, roc_auc CV: {}\".format(get_score(X, y, enabled_transformers = ['cats_ohe', 'cats_positive_probability'], xgb_params=classifier_params))\n",
    "print \"tuned xgb, hold out, roc_auc: {}\".format(make_prediction(\n",
    "    X, y, X_hold_out, y_hold_out,\n",
    "    enabled_transformers = ['cats_ohe', 'cats_positive_probability'], xgb_params=classifier_params\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- замена пропущенных значений числовых признаков - средними значениями\n",
    "- обработка категориальных признаков: OneHotEncoding, замена значения вероятностью  позитивного класса\n",
    "- отбор признаков на основе модели и feature_importances XGBoost\n",
    "- настройка гиперпараметров XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10\\. Подумайте, можно ли еще улучшить модель? Что для этого можно сделать? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "_Можно еще поработать с категориальными признаками – пробовать другие варианты обработки._"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

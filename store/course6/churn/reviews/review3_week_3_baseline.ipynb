{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "import warnings\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 230)\n"
     ]
    }
   ],
   "source": [
    "# читаем csv\n",
    "churn_data_df = pd.read_csv('orange_small_churn_data.txt', sep=',')\n",
    "labels_df = pd.read_csv('orange_small_churn_labels.txt', sep=',', names=['label'])\n",
    "labels_df['target'] = labels_df.label == 1\n",
    "labels_df = labels_df.drop(['label'], axis=1)\n",
    "print churn_data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 212)\n",
      "(4000L,)\n",
      "(36000, 212)\n",
      "(36000L,)\n"
     ]
    }
   ],
   "source": [
    "# готовим \n",
    "columns = churn_data_df.columns\n",
    "columns_numbers = churn_data_df.columns[:190]\n",
    "columns_cat = churn_data_df.columns[-40:]\n",
    "\n",
    "# удаляем признаки не содержащине данных \n",
    "empty_columns = []\n",
    "for col_name in columns:\n",
    "    if len(churn_data_df[col_name].value_counts()) == 0:\n",
    "       empty_columns.append(col_name) \n",
    "\n",
    "columns = [x for x in columns if x not in empty_columns]    \n",
    "columns_numbers = [x for x in columns_numbers if x not in empty_columns]\n",
    "columns_cat = [x for x in columns_cat if x not in empty_columns]\n",
    "\n",
    "data = churn_data_df[columns]\n",
    "data_numbers = churn_data_df[columns_numbers]\n",
    "data_cat = churn_data_df[columns_cat]\n",
    "target = labels_df.target\n",
    "\n",
    "# Hold out выборка \n",
    "X, X_hold_out, y, y_hold_out = train_test_split(data, target, test_size=0.1, random_state=42)\n",
    "print X_hold_out.shape\n",
    "print y_hold_out.shape\n",
    "print X.shape\n",
    "print y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('Var224', (1, 662, '[662L]')),\n",
       "             ('Var215', (1, 563, '[563L]')),\n",
       "             ('Var191', (1, 871, '[871L]')),\n",
       "             ('Var213', (1, 890, '[890L]')),\n",
       "             ('Var208', (2, 39877, '[36823L, 3054L]')),\n",
       "             ('Var201', (2, 10190, '[10184L, 6L]')),\n",
       "             ('Var218', (2, 39440, '[20253L, 19187L]')),\n",
       "             ('Var211', (2, 40000, '[32215L, 7785L]')),\n",
       "             ('Var225', (3, 19065, '[8875L, 8289L, 1901L]')),\n",
       "             ('Var205', (3, 38453, '[25612L, 9232L, 3609L]')),\n",
       "             ('Var194', (3, 10190, '[10015L, 143L, 32L]')),\n",
       "             ('Var223', (4, 35804, '[29279L, 4780L, 1619L, 126L]')),\n",
       "             ('Var229', (4, 17223, '[9312L, 7850L, 31L, 30L]')),\n",
       "             ('Var196', (4, 40000, '[39633L, 351L, 15L, 1L]')),\n",
       "             ('Var203', (5, 39877, '[36192L, 2529L, 1153L, 2L, 1L]')),\n",
       "             ('Var210', (6, 40000, '[38084L, 1206L, 395L, 139L, 121L]')),\n",
       "             ('Var227', (7, 40000, '[28112L, 4928L, 2724L, 1896L, 1818L]')),\n",
       "             ('Var221', (7, 40000, '[29610L, 4960L, 2443L, 1344L, 1320L]')),\n",
       "             ('Var207', (14, 40000, '[28047L, 5526L, 2796L, 1544L, 1005L]')),\n",
       "             ('Var206', (21, 35565, '[13854L, 5151L, 3180L, 2311L, 2260L]')),\n",
       "             ('Var219', (22, 35804, '[32191L, 911L, 883L, 652L, 451L]')),\n",
       "             ('Var226', (23, 40000, '[6403L, 3940L, 3386L, 2374L, 2230L]')),\n",
       "             ('Var195', (23, 40000, '[38353L, 692L, 444L, 146L, 133L]')),\n",
       "             ('Var228', (30, 40000, '[26211L, 3457L, 2111L, 1287L, 1193L]')),\n",
       "             ('Var193', (50, 40000, '[28817L, 5781L, 1763L, 466L, 415L]')),\n",
       "             ('Var212', (78, 40000, '[23433L, 5125L, 2391L, 1162L, 1147L]')),\n",
       "             ('Var204', (100, 40000, '[1464L, 1350L, 1045L, 887L, 881L]')),\n",
       "             ('Var197', (220, 39877, '[3688L, 3583L, 3334L, 2864L, 2365L]')),\n",
       "             ('Var192', (354, 39709, '[313L, 313L, 306L, 305L, 303L]')),\n",
       "             ('Var216', (1819, 40000, '[3929L, 3366L, 2738L, 2456L, 1512L]')),\n",
       "             ('Var222', (3891, 40000, '[3557L, 911L, 619L, 613L, 454L]')),\n",
       "             ('Var220', (3891, 40000, '[3557L, 911L, 619L, 613L, 454L]')),\n",
       "             ('Var198', (3891, 40000, '[3557L, 911L, 619L, 613L, 454L]')),\n",
       "             ('Var199', (4400, 39996, '[746L, 741L, 616L, 515L, 474L]')),\n",
       "             ('Var202', (5542, 39999, '[156L, 108L, 102L, 97L, 96L]')),\n",
       "             ('Var217', (12470, 39440, '[214L, 191L, 172L, 155L, 142L]')),\n",
       "             ('Var200', (13297, 19634, '[51L, 40L, 33L, 28L, 22L]')),\n",
       "             ('Var214', (13297, 19634, '[51L, 40L, 33L, 28L, 22L]'))])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# категориальные признаки \n",
    "\n",
    "columns_with_uniq_values = {}\n",
    "for col_name in columns_cat:\n",
    "    columns_with_uniq_values[col_name] = (\n",
    "        len(data_cat[col_name].value_counts()), \n",
    "        (data_cat[col_name].notnull()).sum(),\n",
    "        str(list(data_cat[col_name].value_counts()[:5])))\n",
    "    \n",
    "ordered = OrderedDict(sorted(columns_with_uniq_values.items(), key=lambda t: t[1][0]))\n",
    "display(ordered)\n",
    "\n",
    "# для признаков с малым кол-вом уникальных значений (n <= 30) будем использовать One Hot Encoding\n",
    "columns_cat_for_one_hot_encoding = [k for k, v in columns_with_uniq_values.iteritems() if v[0] <= 50] \n",
    "\n",
    "# для признаков с большим кол-вом уникальных значений (n > 30) будем использовать специальное преобразование \n",
    "columns_cat_for_trick = [k for k, v in columns_with_uniq_values.iteritems() if v[0] > 50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подготовка признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# вещественные признаки, заполняем нулями пропуски\n",
    "X_num_with_fill_zeros = X[columns_numbers].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Категориальные признаки - One Hot Encoding\n",
    "vectorizer = DictVectorizer(sparse=False)\n",
    "X_cat_with_one_hot_encoding = vectorizer.fit_transform(X[columns_cat_for_one_hot_encoding].fillna('no_data').to_dict('records'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### baseline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# классификаторы\n",
    "CLASSIFIERS = {\n",
    "    'ridge':RidgeClassifier(), \n",
    "    'random forest': RandomForestClassifier(),\n",
    "    'XGBClassifier': XGBClassifier(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(X, y):\n",
    "    \n",
    "    scoring = {'AUC': 'roc_auc', 'precision': 'average_precision'}\n",
    "    \n",
    "    for clf_name, clf in CLASSIFIERS.iteritems():\n",
    "        score = cross_validate(clf, X, y, cv=5, scoring=scoring)\n",
    "        print \"{}:\".format(clf_name)\n",
    "        print \" - roc_auc: {:.4f}\".format(score['test_AUC'].mean())\n",
    "        print \" - average precision: {:.4f}\".format(score['test_precision'].mean())\n",
    "        print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier:\n",
      " - roc_auc: 0.7378\n",
      " - average precision: 0.2165\n",
      "\n",
      "ridge:\n",
      " - roc_auc: 0.6680\n",
      " - average precision: 0.1538\n",
      "\n",
      "random forest:\n",
      " - roc_auc: 0.5880\n",
      " - average precision: 0.1003\n",
      "\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(module='sklearn*', action='ignore', category=DeprecationWarning)\n",
    "get_score(np.hstack((X_num_with_fill_zeros, X_cat_with_one_hot_encoding)), y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
